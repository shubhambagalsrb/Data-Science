{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSUp9IE6M1gQJElRk1ZMoF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhambagalsrb/Data-Science/blob/main/youtube_video_analysis_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hT8MPPS1YyGo"
      },
      "outputs": [],
      "source": [
        "# video_url = \"https://www.youtube.com/watch?v=2gJGnn0a4tk\"\n",
        "\n",
        "video_url = \"https://www.youtube.com/watch?v=TyvYZ26alZs\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai.types import HttpOptions, Part\n",
        "\n",
        "client = genai.Client(http_options=HttpOptions(api_version=\"v1alpha\"),api_key='AIzaSyDZedPp_BPZXjmS9laPVdYSz2tflOEQGps')\n",
        "model_id = \"gemini-2.0-flash-001\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_id,\n",
        "    contents=[\n",
        "        Part.from_uri(\n",
        "            file_uri=video_url,\n",
        "            mime_type=\"video/mp4\",\n",
        "        ),\n",
        "        \"Write a short and engaging blog post based on this video.\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Example response:\n",
        "# Here's a short blog post based on the video provided:\n",
        "#\n",
        "# **Google Turns 25: A Quarter Century of Search!**\n",
        "# ..."
      ],
      "metadata": {
        "id": "m_pjJzAWY0Rj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4BFzbYnkdjl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0sfRkPqadkRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WFGK3dU5dkNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NxM4HvqgdkKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iuO43jjYdkH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RIHH9nVfdkE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jV_i_X8LdkCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VUTc40cPdj_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piXep_YQY-Zs",
        "outputId": "cd55639a-7e0b-42d6-a717-971446fa2171"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here is a short and engaging blog post based on the video:\n",
            "\n",
            "## Boost Your Machine Learning Skills: What are Gradient Boosted Trees?\n",
            "\n",
            "Ready to level up your machine learning game? Let’s dive into gradient-boosted trees! \n",
            "\n",
            "**What are they?**\n",
            "\n",
            "Gradient Boosted Trees, or GBT, are a popular model ensembling method that performs regression or classification by combining the outputs from individual decision trees.\n",
            "\n",
            "**Boosting: the magic sauce**\n",
            "\n",
            "Unlike Random Forests, which build many independent decision trees in parallel, GBT uses a technique called *boosting*.  Boosting combines “weak learners” (typically simple decision trees with only one split, called decision stumps) sequentially. The big idea? Each new tree tries to correct the errors made by the previous ones. The boosting method finds the direction in which the loss decreases the fastest. This is given by the negative derivative of loss with respect to the previous model's output. It's like having a team of experts who each focus on patching the holes left by the others.\n",
            "<br>\n",
            "**Loss Function?**\n",
            "\n",
            "The model calculates the model accuracy using the Loss Function, where `P` is the label and `Q` is the prediction.  Basically, loss is high when the label and prediction do not agree, and loss is zero when they are in perfect agreement. \n",
            "<br>\n",
            "**Learning Rate?**\n",
            "\n",
            "The equation for the model is as follows: *Boosted Ensemble = First Tree + eta * Second Tree*.\n",
            "\n",
            "We want to choose the learning rate such that we don't walk too far in any direction. But at the same time, if the learning rate is too low, then the model might take too long to converge to the right answer.\n",
            "<br>\n",
            "**GBT & M-nist**\n",
            "\n",
            "The video then fits a gradient-boosted trees model using the XGBoost library on M-nist with 330 weak learners and achieved 89% accuracy.\n",
            "\n",
            "**Key Differences to Random Forests**\n",
            "\n",
            "-   **Sequential vs Parallel:** GBT builds trees sequentially, while Random Forests build them in parallel.\n",
            "-   **Boosting vs Bagging:** GBT uses boosting; Random Forests use bagging.\n",
            "-   **Complex Boundaries:** GBT can model very complex relationships and decision boundaries.\n",
            "\n",
            "**The Downside:**\n",
            "\n",
            "*Overfitting* can occur because GBT's have a high model capacity.\n",
            "\n",
            "**Want to try it for yourself?** Check the code in the video's description and see how far you can push your models!  Don't forget to subscribe for more ML insights!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai.types import HttpOptions, Part\n",
        "\n",
        "client = genai.Client(http_options=HttpOptions(api_version=\"v1alpha\"),api_key='AIzaSyDZedPp_BPZXjmS9laPVdYSz2tflOEQGps')\n",
        "model_id = \"gemini-2.0-flash-001\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model_id,\n",
        "    contents=[\n",
        "        Part.from_uri(\n",
        "            file_uri=video_url,\n",
        "            mime_type=\"video/mp4\",\n",
        "        ),\n",
        "        \"Given the following content, generate a set of insightful and relevant questions that test comprehension, encourage critical thinking, and highlight key points from the material. Ensure the questions vary in difficulty (easy, medium, hard) and cover different types (e.g., factual, analytical, application-based) based on this video.\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Example response:\n",
        "# Here's a short blog post based on the video provided:\n",
        "#\n",
        "# **Google Turns 25: A Quarter Century of Search!**\n",
        "# ..."
      ],
      "metadata": {
        "id": "NjpUy9byeZSq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TFTV7p0fH3R",
        "outputId": "03b90a07-a7a9-4450-a59b-6d1d580ae6c7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some questions about the video, categorized by difficulty:\n",
            "\n",
            "**Factual (Easy):**\n",
            "\n",
            "1.  What is the name of the model ensembling method discussed in the video?\n",
            "2.  What type of task is performed using gradient boosted trees in the video?\n",
            "3.  What dataset is used to test the classification model?\n",
            "\n",
            "**Analytical (Medium):**\n",
            "\n",
            "1.  What is model ensembling, as introduced in the Random Forests video?\n",
            "2.  How do gradient boosted trees differ from random forests in the way they combine individual trees?\n",
            "3.  What are decision stumps, as used in gradient boosted trees, and why are they called \"weak learners\"?\n",
            "4.  What is the purpose of a loss function? How is it used to evaluate a model's performance in this context?\n",
            "5.  Why is a learning rate essential in the context of gradient boosting? What happens if the learning rate is too high or too low?\n",
            "\n",
            "**Application-Based/Critical Thinking (Hard):**\n",
            "\n",
            "1.  Explain, in your own words, how boosting combines weak learners sequentially to improve prediction accuracy.\n",
            "2.  The video mentions that gradient boosted trees have a lot of model capacity and can model complex relationships, but are also prone to overfitting. Discuss potential strategies to mitigate overfitting in gradient boosted trees.\n",
            "3.  The equations for Cross Entropy and fitting the Second Tree on the derivative of L with respect to F(1) are shown, but not explained in detail. Briefly research and explain the intuition behind using the negative gradient of the loss function to guide the construction of subsequent trees.\n",
            "4.  The video provides a link to a Python implementation. What steps would you take to experiment with different hyperparameters (e.g., number of estimators, learning rate, maximum depth) in the Python code and how would you evaluate the impact of these choices?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vf5AoIk_feqF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}